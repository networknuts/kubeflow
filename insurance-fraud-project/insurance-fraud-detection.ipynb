{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b1657da3-edd4-4268-a0ce-e8a6e28c3a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports\n",
    "import kfp\n",
    "from kfp import dsl\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ba350ee7-2b07-4c7c-975c-39f967ee83f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.component(\n",
    "    base_image=\"quay.io/jupyter/scipy-notebook:lab-4.4.3\",\n",
    "    packages_to_install=[\"pandas\",\"numpy\",\"scikit-learn\",\"joblib\",\"minio\"]\n",
    ")\n",
    "def preprocess_op(\n",
    "    raw_csv:  dsl.Input[dsl.Artifact],\n",
    "    clean_csv: dsl.Output[dsl.Artifact],\n",
    "    prep_joblib: dsl.Output[dsl.Artifact],\n",
    "    train_path: dsl.Output[dsl.Artifact],\n",
    "    test_path:  dsl.Output[dsl.Artifact],\n",
    "):\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import pickle\n",
    "    import joblib\n",
    "    from minio import Minio\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.compose import ColumnTransformer\n",
    "    from sklearn.impute import SimpleImputer\n",
    "    from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "    # 1️⃣ Load & basic clean\n",
    "    df = pd.read_csv(raw_csv.path)\n",
    "    df = df.replace(r'^\\s*$', np.nan, regex=True).fillna('NA')\n",
    "    drop_cols = [\n",
    "        'policy_number',\n",
    "        'policy_bind_date',\n",
    "        'incident_date',\n",
    "        'incident_location',\n",
    "        '_c39'\n",
    "    ]\n",
    "    df = df.drop(columns=[c for c in drop_cols if c in df.columns])\n",
    "\n",
    "    # 2️⃣ Persist cleaned CSV artifact (ephemeral)\n",
    "    df.to_csv(clean_csv.path, index=False)\n",
    "\n",
    "    # 3️⃣ Push cleaned CSV to stable MinIO path\n",
    "    client = Minio(\n",
    "        endpoint=\"minio-service.kubeflow:9000\",\n",
    "        access_key=\"minio\",\n",
    "        secret_key=\"minio123\",\n",
    "        secure=False\n",
    "    )\n",
    "    client.fput_object(\n",
    "        \"mlpipeline\",\n",
    "        \"insurance/insurance_fraud_cleaned.csv\",\n",
    "        clean_csv.path\n",
    "    )\n",
    "\n",
    "    # 4️⃣ Build & fit feature‐engineering pipeline\n",
    "    X = df.drop('fraud_reported', axis=1)\n",
    "    y = df['fraud_reported'].map({'Y':1,'N':0})\n",
    "\n",
    "    numeric_cols = X.select_dtypes(include=['int64','float64']).columns.tolist()\n",
    "    categorical_cols = X.select_dtypes(include=['object','category']).columns.tolist()\n",
    "    if 'insured_zip' in numeric_cols:\n",
    "        numeric_cols.remove('insured_zip')\n",
    "        categorical_cols.append('insured_zip')\n",
    "\n",
    "    num_pipe = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler',  StandardScaler())\n",
    "    ])\n",
    "    cat_pipe = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='Missing')),\n",
    "        ('ohe',      OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "    fe = ColumnTransformer([\n",
    "        ('num', num_pipe, numeric_cols),\n",
    "        ('cat', cat_pipe, categorical_cols)\n",
    "    ])\n",
    "\n",
    "    fe.fit(X, y)\n",
    "\n",
    "    # 5️⃣ Persist preprocessor to stable MinIO path & as component output\n",
    "    fe_path = prep_joblib.path\n",
    "    joblib.dump(fe, fe_path)\n",
    "    client.fput_object(\n",
    "        \"mlpipeline\",\n",
    "        \"insurance/preprocessor.joblib\",\n",
    "        fe_path\n",
    "    )\n",
    "\n",
    "    # 6️⃣ Transform, split, and serialize train/test sets\n",
    "    X_fe = fe.transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_fe, y, test_size=0.2, stratify=y, random_state=42\n",
    "    )\n",
    "\n",
    "    with open(train_path.path, 'wb') as f:\n",
    "        pickle.dump((X_train, y_train), f)\n",
    "    with open(test_path.path,  'wb') as f:\n",
    "        pickle.dump((X_test,  y_test),  f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "09c290d7-58e3-41a6-8402-1bd3a4b46a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.component(base_image=\"quay.io/jupyter/scipy-notebook:lab-4.4.3\")\n",
    "def train_op(\n",
    "    train_data: dsl.Input[dsl.Artifact],\n",
    "    model_output: dsl.Output[dsl.Model],\n",
    "):\n",
    "    import pickle\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "    # Load numeric arrays\n",
    "    with open(train_data.path, 'rb') as f:\n",
    "        X_train, y_train = pickle.load(f)\n",
    "\n",
    "    # Train\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Dump\n",
    "    with open(model_output.path, 'wb') as f:\n",
    "        pickle.dump(clf, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7d543b12-ecbc-4e3f-bdca-b6452735a527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Eval component\n",
    "@dsl.component(base_image=\"quay.io/jupyter/scipy-notebook:lab-4.4.3\")\n",
    "def eval_op(\n",
    "    test_data:  dsl.Input[dsl.Artifact],\n",
    "    model_input: dsl.Input[dsl.Model],\n",
    "):\n",
    "    import pickle\n",
    "    from sklearn.metrics import accuracy_score\n",
    "\n",
    "    # 1️⃣ Load test split & model\n",
    "    with open(test_data.path,  'rb') as f:\n",
    "        X_test, y_test = pickle.load(f)\n",
    "    with open(model_input.path, 'rb') as f:\n",
    "        clf = pickle.load(f)\n",
    "\n",
    "    # 2️⃣ Compute & print accuracy\n",
    "    acc = accuracy_score(y_test, clf.predict(X_test))\n",
    "    print(f\"Model accuracy: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4469ed08-996a-481c-b94d-dd0464f5a192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Define the pipeline\n",
    "@dsl.pipeline(name=\"insurance-fraud-detection-v2\")\n",
    "def fraud_pipeline(\n",
    "    raw_csv: str = \"minio://mlpipeline/insurance_claims.csv\"\n",
    "):\n",
    "    # Import raw CSV from MinIO (or UI-uploaded artifact) via an ImporterOp\n",
    "    from kfp.v2.dsl import importer, Dataset\n",
    "    raw_data = importer(\n",
    "        artifact_uri=raw_csv,\n",
    "        artifact_class=Dataset,\n",
    "        reimport=True,\n",
    "    )\n",
    "\n",
    "    # 1) clean & split\n",
    "    prep = preprocess_op(raw_csv=raw_data.output)\n",
    "\n",
    "    # 2) train\n",
    "    train = train_op(train_data=prep.outputs[\"train_path\"])\n",
    "\n",
    "    # 3) eval\n",
    "    eval_op(\n",
    "        test_data=prep.outputs[\"test_path\"],\n",
    "        model_input=train.outputs[\"model_output\"]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "635cc712-c233-4663-8e13-02ec3c42a3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Generated insurance_fraud_pipeline_v12.yaml\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Compile to YAML\n",
    "from kfp.v2 import compiler\n",
    "compiler.Compiler().compile(\n",
    "    pipeline_func=fraud_pipeline,\n",
    "    package_path=\"insurance_fraud_pipeline_v12.yaml\"\n",
    ")\n",
    "print(\"✅ Generated insurance_fraud_pipeline_v12.yaml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "88b126fb-9ae0-4897-8016-bd6d52cdf6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinIO endpoint: None\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"MinIO endpoint:\", os.environ.get(\"accesskey\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429c7df3-e403-412c-b2f4-de863e73f1dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
