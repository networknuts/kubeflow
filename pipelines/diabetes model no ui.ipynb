{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05c7e3a4-f593-4866-af2b-f68d4dd0ab5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_394/4055913130.py:1: DeprecationWarning: The module `kfp.v2` is deprecated and will be removed in a futureversion. Please import directly from the `kfp` namespace, instead of `kfp.v2`.\n",
      "  from kfp.v2.dsl import (\n"
     ]
    }
   ],
   "source": [
    "from kfp.v2.dsl import (\n",
    "    component, \n",
    "    pipeline, \n",
    "    Input, \n",
    "    Output, \n",
    "    Dataset, \n",
    "    Model, \n",
    "    Metrics\n",
    ")\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "247f12f5-8a26-4d8c-b010-ae2c3ece7caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp.v2.dsl import component, Output, Dataset\n",
    "\n",
    "@component(\n",
    "    base_image=\"python:3.9-slim\",\n",
    "    packages_to_install=[\"pandas\", \"pyarrow\"]  # added pyarrow for Parquet support\n",
    ")\n",
    "def load_data_op(\n",
    "    csv_path: str,\n",
    "    data: Output[Dataset]\n",
    "):\n",
    "    \"\"\"Load CSV from `csv_path` and write it out as a Dataset (Parquet).\"\"\"\n",
    "    import pandas as pd\n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df.to_parquet(data.path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b58abe3-c495-4f98-9015-aabde361868e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp.v2.dsl import (\n",
    "    component,\n",
    "    Input,\n",
    "    Output,\n",
    "    Dataset\n",
    ")\n",
    "\n",
    "@component(\n",
    "    base_image=\"python:3.9-slim\",\n",
    "    packages_to_install=[\"pandas\", \"scikit-learn\", \"pyarrow\"]\n",
    ")\n",
    "def preprocess_and_split_op(\n",
    "    data: Input[Dataset],\n",
    "    X_train: Output[Dataset],\n",
    "    X_test: Output[Dataset],\n",
    "    y_train: Output[Dataset],\n",
    "    y_test: Output[Dataset],\n",
    "    test_size: float = 0.2,\n",
    "    random_state: int = 0\n",
    "):\n",
    "    \"\"\"Split into features & target, then train/test splits.\"\"\"\n",
    "    import pandas as pd\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    # 1. Read the parquet-formatted input\n",
    "    df = pd.read_parquet(data.path)\n",
    "\n",
    "    # 2. Separate features and label\n",
    "    X = df.drop(\"Outcome\", axis=1)\n",
    "    y = df[\"Outcome\"]\n",
    "\n",
    "    # 3. Do the split\n",
    "    Xtr, Xte, ytr, yte = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "\n",
    "    # 4. Write out each split as a Dataset (Parquet)\n",
    "    Xtr.to_parquet(X_train.path, index=False)\n",
    "    Xte.to_parquet(X_test.path, index=False)\n",
    "\n",
    "    # Wrap the Series in a DataFrame so we can parquet it\n",
    "    pd.DataFrame({\"Outcome\": ytr}).to_parquet(y_train.path, index=False)\n",
    "    pd.DataFrame({\"Outcome\": yte}).to_parquet(y_test.path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd835f06-a578-4dd5-8887-1f9b3174c82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp.v2.dsl import component, Input, Output, Dataset, Model\n",
    "\n",
    "@component(\n",
    "    base_image=\"python:3.9-slim\",\n",
    "    packages_to_install=[\"pandas\", \"scikit-learn\", \"joblib\", \"pyarrow\"]\n",
    ")\n",
    "def train_model_op(\n",
    "    X_train: Input[Dataset],\n",
    "    y_train: Input[Dataset],\n",
    "    model: Output[Model],\n",
    "    penalty: str = \"l2\",\n",
    "    C: float = 1.0,\n",
    "    max_iter: int = 300\n",
    "):\n",
    "    \"\"\"Train a LogisticRegression model and save it.\"\"\"\n",
    "    import joblib\n",
    "    import pandas as pd\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "    # Load the train splits (Parquet)\n",
    "    Xtr = pd.read_parquet(X_train.path)\n",
    "    ytr = pd.read_parquet(y_train.path)\n",
    "\n",
    "    # Train\n",
    "    clf = LogisticRegression(penalty=penalty, C=C, max_iter=max_iter)\n",
    "    clf.fit(Xtr, ytr)\n",
    "\n",
    "    # Persist model\n",
    "    joblib.dump(clf, model.path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebe8546c-c2f8-4133-af88-2eec38042eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp.v2.dsl import component, Input, Output, Model, Dataset, Metrics\n",
    "\n",
    "@component(\n",
    "    base_image=\"python:3.9-slim\",\n",
    "    packages_to_install=[\"pandas\", \"scikit-learn\", \"joblib\", \"pyarrow\"]\n",
    ")\n",
    "def evaluate_model_op(\n",
    "    model: Input[Model],\n",
    "    X_test: Input[Dataset],\n",
    "    y_test: Input[Dataset],\n",
    "    report: Output[Metrics]\n",
    "):\n",
    "    \"\"\"Generate classification report and emit as JSON.\"\"\"\n",
    "    import joblib\n",
    "    import json\n",
    "    import pandas as pd\n",
    "    from sklearn.metrics import classification_report\n",
    "\n",
    "    # Load model\n",
    "    clf = joblib.load(model.path)\n",
    "\n",
    "    # Read test splits (Parquet)\n",
    "    Xte = pd.read_parquet(X_test.path)\n",
    "    yte = pd.read_parquet(y_test.path)\n",
    "\n",
    "    # Predict and build report\n",
    "    preds = clf.predict(Xte)\n",
    "    rpt = classification_report(yte, preds, output_dict=True)\n",
    "\n",
    "    # Write out JSON metrics\n",
    "    with open(report.path, \"w\") as f:\n",
    "        json.dump(rpt, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f83b3864-d1c9-4f75-9b79-9123cfdb7316",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "from kfp.v2.dsl import component, Input, Output, Model, Dataset\n",
    "\n",
    "@component(\n",
    "    base_image=\"python:3.9-slim\",\n",
    "    packages_to_install=[\"pandas\", \"joblib\", \"scikit-learn\"]\n",
    ")\n",
    "def predict_samples_op(\n",
    "    model: Input[Model],\n",
    "    samples: Dict[str, List[Dict]],\n",
    "    predictions: Output[Dataset],\n",
    "):\n",
    "    \"\"\"Run model.predict on a list of sample records and write out JSON.\"\"\"\n",
    "    import joblib\n",
    "    import pandas as pd\n",
    "    import json\n",
    "\n",
    "    # 1. Load the trained model\n",
    "    clf = joblib.load(model.path)\n",
    "\n",
    "    # 2. Build a DataFrame from the incoming dict\n",
    "    df = pd.DataFrame(samples[\"records\"])\n",
    "\n",
    "    # 3. Reorder columns to match training, if possible\n",
    "    if hasattr(clf, \"feature_names_in_\"):\n",
    "        df = df[clf.feature_names_in_]\n",
    "\n",
    "    # 4. Generate predictions\n",
    "    preds = clf.predict(df)\n",
    "    classes = (\"No diabetes\", \"Diabetes\")\n",
    "    result = [classes[int(p)] for p in preds]\n",
    "\n",
    "    # 5. Write JSON to the Dataset artifact\n",
    "    with open(predictions.path, \"w\") as f:\n",
    "        json.dump(result, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ba970bb-067e-4461-956d-68476ed19d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline(name=\"diabetes-logreg-pipeline\", description=\"Logistic regression on diabetes\")\n",
    "def diabetes_pipeline(\n",
    "    csv_path: str = \"/mnt/data/diabetes.csv\",\n",
    "    test_size: float = 0.2,\n",
    "    random_state: int = 0,\n",
    "    penalty: str = \"l2\",\n",
    "    C: float = 1.0,\n",
    "    max_iter: int = 300\n",
    "):\n",
    "    # 1. Load data\n",
    "    data = load_data_op(csv_path=csv_path)\n",
    "\n",
    "    # 2. Split\n",
    "    splits = preprocess_and_split_op(\n",
    "        data=data.output,\n",
    "        test_size=test_size,\n",
    "        random_state=random_state\n",
    "    )\n",
    "\n",
    "    # 3. Train\n",
    "    model = train_model_op(\n",
    "        X_train=splits.outputs[\"X_train\"],\n",
    "        y_train=splits.outputs[\"y_train\"],\n",
    "        penalty=penalty,\n",
    "        C=C,\n",
    "        max_iter=max_iter\n",
    "    )\n",
    "\n",
    "    # 4. Evaluate\n",
    "    report = evaluate_model_op(\n",
    "        model=model.output,\n",
    "        X_test=splits.outputs[\"X_test\"],\n",
    "        y_test=splits.outputs[\"y_test\"]\n",
    "    )\n",
    "\n",
    "    # 5. Predict on sample cases\n",
    "    sample_records = {\n",
    "        \"records\": [\n",
    "            {\n",
    "                \"Pregnancies\": 6.0,\n",
    "                \"Glucose\": 110.0,\n",
    "                \"BloodPressure\": 65.0,\n",
    "                \"SkinThickness\": 15.0,\n",
    "                \"Insulin\": 1.0,\n",
    "                \"BMI\": 45.7,\n",
    "                \"DiabetesPedigreeFunction\": 0.627,\n",
    "                \"Age\": 50\n",
    "            },\n",
    "            {\n",
    "                \"Pregnancies\": 0,\n",
    "                \"Glucose\": 88.0,\n",
    "                \"BloodPressure\": 60.0,\n",
    "                \"SkinThickness\": 35.0,\n",
    "                \"Insulin\": 1.0,\n",
    "                \"BMI\": 45.7,\n",
    "                \"DiabetesPedigreeFunction\": 0.27,\n",
    "                \"Age\": 20\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    predict_samples_op(\n",
    "        model=model.output,\n",
    "        samples=sample_records\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e01e5216-b5da-494b-8bfb-1786a3d602d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    from kfp.v2 import compiler\n",
    "    compiler.Compiler().compile(\n",
    "        pipeline_func=diabetes_pipeline,\n",
    "        package_path=\"diabetes_pipeline.yaml\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c68fd1-eb68-4221-9a17-a943e7f9483e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
